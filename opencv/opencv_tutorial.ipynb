{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading image, videos, webcam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('resources/lena.png')\n",
    "cv2.imshow('Output', img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-5f1fca9a751a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVideoCapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'resources/test_video.mp4'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'video'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;36m0xFF\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'q'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture('resources/test_video.mp4')\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    cv2.imshow('video', img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        cv2.destroyAllWindows()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3, 640)\n",
    "cap.set(4, 480)\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    cv2.imshow('video', img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        cv2.destroyAllWindows()\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('resources/lena.png')\n",
    "kernel = np.ones((5,5), np.uint8)\n",
    "\n",
    "imgGray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "imgBlur = cv2.GaussianBlur(imgGray, (7,7), 0)\n",
    "imgCanny = cv2.Canny(img, 100, 100)\n",
    "imgCanny2 = cv2.Canny(img, 150, 200)\n",
    "imgDialation = cv2.dilate(imgCanny2, kernel, iterations=1)\n",
    "imgEroded = cv2.erode(imgDialation, kernel)\n",
    "\n",
    "# cv2.imshow('gray', imgGray)\n",
    "# cv2.imshow('blur', imgBlur)\n",
    "# cv2.imshow('canny', imgCanny)\n",
    "cv2.imshow('canny2', imgCanny2)\n",
    "cv2.imshow('dialation', imgDialation)\n",
    "cv2.imshow('eroded', imgEroded)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resizing and cropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(225, 225, 3)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "img = cv2.imread('resources/lena.png')\n",
    "print(img.shape)\n",
    "\n",
    "imgResize = cv2.resize(img, (150, 150))\n",
    "imgCroped = img[50:, :150]\n",
    "\n",
    "cv2.imshow('image', img)\n",
    "cv2.imshow('resize', imgResize)\n",
    "cv2.imshow('crope', imgCroped)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shapes and text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = np.zeros((512, 512, 3), np.uint8)\n",
    "cv2.line(img, (0, 0), (300, 300), (0, 255, 0), 3)\n",
    "cv2.rectangle(img, (0, 0), (250, 350), (0, 0, 255), 2)\n",
    "cv2.putText(img, 'opencv', (300, 100), cv2.FONT_ITALIC, 1, (0, 150,0 ), 1)\n",
    "\n",
    "cv2.imshow('img', img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Warp perspective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('resources/cards.png')\n",
    "\n",
    "width, height = 250, 350\n",
    "\n",
    "pts1 = np.float32([[111, 219], [287, 188], [154, 482], [352, 440]])\n",
    "pts2 = np.float32([[0,0], [width,0], [0,height], [width, height]])\n",
    "\n",
    "matrix = cv2.getPerspectiveTransform(pts1, pts2)\n",
    "imgOutput = cv2.warpPerspective(img, matrix, (width, height))\n",
    "\n",
    "cv2.imshow('img', img)\n",
    "cv2.imshow('warp img', imgOutput)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joining images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img = cv2.imread('resources/lena.png')\n",
    "# img should have one depth (RGB & RGB, grayscale ...)\n",
    "imgHor = np.hstack((img, img))\n",
    "imgVer = np.vstack((img, img))\n",
    "\n",
    "cv2.imshow('img hstack', imgHor)\n",
    "cv2.imshow('img vstack', imgVer)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from utils import stackImages\n",
    "\n",
    "img = cv2.imread('resources/lena.png')\n",
    "stackedImage = stackImages(0.5, ([img], [img])) # [img, img] to hstack\n",
    "cv2.imshow('img stack', stackedImage)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Color detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from utils import stackImages\n",
    "\n",
    "def empty(a):\n",
    "    pass\n",
    "\n",
    "cv2.namedWindow('trackBars')\n",
    "cv2.resizeWindow('trackBars', 640, 240)\n",
    "cv2.createTrackbar('Hue min', 'trackBars', 0, 179, empty)\n",
    "cv2.createTrackbar('Hue max', 'trackBars', 179, 179, empty)\n",
    "cv2.createTrackbar('Sat min', 'trackBars', 48, 255, empty)\n",
    "cv2.createTrackbar('Sat max', 'trackBars', 255, 255, empty)\n",
    "cv2.createTrackbar('Val min', 'trackBars', 147, 255, empty)\n",
    "cv2.createTrackbar('Val max', 'trackBars', 255, 255, empty)\n",
    "\n",
    "while True:\n",
    "    img = cv2.imread('resources/lambo.png')\n",
    "    imgHSV = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    h_min = cv2.getTrackbarPos('Hue min', 'trackBars')\n",
    "    h_max = cv2.getTrackbarPos('Hue max', 'trackBars')\n",
    "    s_min = cv2.getTrackbarPos('Sat min', 'trackBars')\n",
    "    s_max = cv2.getTrackbarPos('Sat max', 'trackBars')\n",
    "    v_min = cv2.getTrackbarPos('Val min', 'trackBars')\n",
    "    v_max = cv2.getTrackbarPos('Val max', 'trackBars')\n",
    "\n",
    "    lower = np.array([h_min, s_min, v_min])\n",
    "    upper = np.array([h_max, s_max, v_max])\n",
    "    mask = cv2.inRange(imgHSV, lower, upper)\n",
    "    imgResult = cv2.bitwise_and(img, img, mask=mask)\n",
    "        \n",
    "    imgStack = stackImages(0.6, ([img, imgHSV], [mask, imgResult]))\n",
    "    cv2.imshow('stecked', imgStack)\n",
    "    cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contours/shape detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from utils import stackImages\n",
    "\n",
    "def getContours(img):\n",
    "    _, contours, hierarchy = cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    for cnt in contours:\n",
    "        area = cv2.contourArea(cnt)\n",
    "        if area > 500:\n",
    "            cv2.drawContours(imgContour, cnt, -1, (255, 0, 0), 3)\n",
    "            peri = cv2.arcLength(cnt, True)\n",
    "            approx = cv2.approxPolyDP(cnt, 0.02*peri, True)\n",
    "            objCor = len(approx)\n",
    "            x, y, w, h = cv2.boundingRect(approx)\n",
    "            \n",
    "            if objCor == 3: objectType = 'Tri'\n",
    "            elif objCor == 4:\n",
    "                aspRatio = w/float(h)\n",
    "                if aspRatio> 0.95 and aspRatio < 1.05:\n",
    "                    objectType = 'Square'\n",
    "                else:\n",
    "                    objectType = 'Rectangle'\n",
    "            elif objCor > 4: objectType = 'Circle'\n",
    "            else: objectType = None\n",
    "            \n",
    "            cv2.rectangle(imgContour, (x,y), (x+w, y+h), (0, 255, 0), 2)\n",
    "            cv2.putText(imgContour, objectType,\n",
    "                       (x+(w//2) + 10, y+(h//2)-10), cv2.FONT_ITALIC, 0.8,\n",
    "                       (0, 0, 0), 2)\n",
    "            \n",
    "\n",
    "img = cv2.imread('resources/shapes.png')\n",
    "imgContour = img.copy()\n",
    "\n",
    "imgGray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "imgBlur = cv2.GaussianBlur(imgGray, (7,7), 1)\n",
    "imgCanny = cv2.Canny(imgBlur, 50, 50)\n",
    "\n",
    "imgBlank = np.zeros_like(img)\n",
    "\n",
    "getContours(imgCanny)\n",
    "\n",
    "imgStack = stackImages(0.8, ([img, imgGray, imgBlur],\n",
    "                             [imgCanny, imgContour, imgBlank]))\n",
    "\n",
    "cv2.imshow('Stack', imgStack)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Face detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "faceCascade = cv2.CascadeClassifier('resources/haarcascades/haarcascade_frontalface_default.xml')\n",
    "img = cv2.imread('resources/lena.png')\n",
    "imgGray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "faces = faceCascade.detectMultiScale(imgGray, 1.1,4)\n",
    "\n",
    "for (x,y,w,h) in faces:\n",
    "    cv2.rectangle(img, (x,y), (x+w, y+h), (255, 0, 0), 2)\n",
    "    \n",
    "\n",
    "cv2.imshow('Output', img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
